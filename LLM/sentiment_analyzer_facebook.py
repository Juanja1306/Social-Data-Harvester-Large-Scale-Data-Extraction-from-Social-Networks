import pandas as pd
from google import genai
from google.genai import types
import os
import time
import json
from dotenv import load_dotenv

# --- CONFIGURACI칍N INICIAL ---
load_dotenv(os.path.join(os.getcwd(), '.env'))
api_key = os.getenv("GEMINI_API_KEY")

client = genai.Client(api_key=api_key) if api_key else None
MODELO_USADO = "gemini-2.0-flash" 

def clean_data_for_llm(text):
    """
    Optimizaci칩n de Tokens:
    1. Trunca textos excesivamente largos (ahorra cuota).
    2. Elimina saltos de l칤nea innecesarios.
    """
    if not isinstance(text, str):
        return ""
    # Recortamos a los primeros 300 caracteres. 
    # Para an치lisis de sentimiento, el "n칰cleo" suele estar al inicio.
    return text[:300].replace('\n', ' ').strip()

def generate_global_analysis(posts_text):
    """
    Env칤a TODO el contexto a Gemini para obtener un informe ejecutivo.
    Maneja reintentos autom치ticos si sale error 429.
    """
    if not client:
        return {"error": "API Key no configurada"}

    prompt = (
        f"Analiza el siguiente conjunto de publicaciones extra칤das de Facebook:\n\n"
        f"{posts_text}\n\n"
        "--- INSTRUCCIONES ---\n"
        "Act칰a como un Cient칤fico de Datos experto. Genera un reporte final en formato JSON "
        "con las siguientes claves exactas:\n"
        "1. 'total_analizados': (n칰mero entero)\n"
        "2. 'distribucion_sentimientos': Objeto con porcentajes estimados {'positivo': %, 'negativo': %, 'neutral': %}\n"
        "3. 'temas_principales': Lista de 3 temas recurrentes.\n"
        "4. 'conclusion_general': Un resumen ejecutivo de 1 p치rrafo (m치x 50 palabras) sobre la percepci칩n p칰blica.\n"
        "5. 'rendimiento_modelo': 'Gemini 2.0 Flash'\n\n"
        "Responde SOLO con el JSON."
    )

    # Sistema de Reintentos (Backoff)
    max_retries = 3
    wait_time = 10 # Segundos iniciales

    for attempt in range(max_retries):
        try:
            response = client.models.generate_content(
                model=MODELO_USADO,
                contents=prompt,
                config=types.GenerateContentConfig(
                    response_mime_type="application/json"
                )
            )
            return json.loads(response.text)

        except Exception as e:
            error_str = str(e)
            if "429" in error_str or "RESOURCE_EXHAUSTED" in error_str:
                print(f"丘멆잺 [Cuota Excedida] Esperando {wait_time}s para reintentar (Intento {attempt+1}/{max_retries})...")
                time.sleep(wait_time)
                wait_time *= 2 # Espera exponencial: 10s -> 20s -> 40s
            else:
                return {"error": f"Error t칠cnico irrecuperable: {error_str}"}
    
    return {"error": "Se agotaron los intentos de conexi칩n con Gemini."}

def start_gemini_analysis(csv_file="resultados.csv"):
    """
    Funci칩n principal llamada desde el Main.
    Procesa, Analiza y Retorna un reporte textual.
    """
    if not os.path.exists(csv_file):
        return "Error: No se encontr칩 el archivo de datos."

    try:
        print("[AI] Cargando datos de Facebook...")
        start_total = time.time()
        
        df = pd.read_csv(csv_file)
        df['RedSocial'] = df['RedSocial'].astype(str)
        df_facebook = df[df['RedSocial'] == 'Facebook'].copy()
        
        if df_facebook.empty:
            return "No hay datos de Facebook para analizar."

        # 1. Pre-procesamiento para ahorrar tokens (Vital para cuenta gratuita)
        print(f"[AI] Optimizando {len(df_facebook)} registros para el LLM...")
        # Concatenamos todos los posts en un solo bloque de texto numerado
        all_posts_clean = ""
        for idx, row in df_facebook.iterrows():
            clean_text = clean_data_for_llm(row['Data'])
            if len(clean_text) > 20: # Ignoramos textos muy cortos o vac칤os
                all_posts_clean += f"Post {idx}: {clean_text} | "

        # Verificaci칩n de seguridad
        if not all_posts_clean:
            return "La data extra칤da no contiene texto v치lido para analizar."

        print("[AI] Enviando macro-an치lisis a Gemini (esto puede tardar unos segundos)...")
        
        # 2. Llamada al An치lisis Global
        resultado_json = generate_global_analysis(all_posts_clean)
        
        end_total = time.time()
        tiempo_ejecucion = end_total - start_total

        # 3. Formatear la respuesta para mostrar en el Main
        if "error" in resultado_json:
            return f"Error en an치lisis: {resultado_json['error']}"

        # Construcci칩n del Reporte de Texto para el usuario
        dist = resultado_json.get('distribucion_sentimientos', {})
        temas = ", ".join(resultado_json.get('temas_principales', []))
        
        reporte = (
            f"=== REPORTE DE AN츼LISIS DE SENTIMIENTOS (Facebook) ===\n"
            f"Modelo: {MODELO_USADO}\n"
            f"Tiempo de Ejecuci칩n: {tiempo_ejecucion:.2f} segundos\n"
            f"Registros Procesados: {len(df_facebook)}\n"
            f"----------------------------------------\n"
            f"游늵 Distribuci칩n:\n"
            f"   Positivo: {dist.get('positivo', 'N/A')}%\n"
            f"   Negativo: {dist.get('negativo', 'N/A')}%\n"
            f"   Neutral:  {dist.get('neutral', 'N/A')}%\n"
            f"----------------------------------------\n"
            f"游댐 Temas Clave: {temas}\n"
            f"----------------------------------------\n"
            f"游닇 Conclusi칩n:\n{resultado_json.get('conclusion_general', 'Sin conclusi칩n')}\n"
        )
        
        # Opcional: Guardar este reporte en un txt para el informe
        with open("reporte_facebook_gemini.txt", "w", encoding="utf-8") as f:
            f.write(reporte)
            
        return reporte

    except Exception as e:
        import traceback
        traceback.print_exc()
        return f"Error cr칤tico en el m칩dulo AI: {str(e)}"